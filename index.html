<!DOCTYPE html>
<html>
<head>
    <title>Teste Facial - Radar</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body { margin: 0; display: flex; flex-direction: column; align-items: center; font-family: sans-serif; background: #f0f2f5; }
        canvas { position: absolute; }
        #video-container { position: relative; margin-top: 20px; border-radius: 10px; overflow: hidden; box-shadow: 0 4px 10px rgba(0,0,0,0.2); }
        #status { padding: 20px; font-weight: bold; color: #2563eb; }
    </style>
</head>
<body>
    <div id="status">Carregando IA... Aguarde.</div>
    <div id="video-container">
        <video id="video" width="320" height="240" autoplay muted playsinline></video>
    </div>

    <script>
        const video = document.getElementById('video');
        const status = document.getElementById('status');

        // 1. Carregar os modelos da pasta /models
        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('./models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
            faceapi.nets.faceRecognitionNet.loadFromUri('./models')
        ]).then(startVideo);

        function startVideo() {
            navigator.mediaDevices.getUserMedia({ video: {} })
                .then(stream => {
                    video.srcObject = stream;
                    status.innerText = "IA Pronta! Identificando...";
                })
                .catch(err => status.innerText = "Erro ao acessar câmera: " + err);
        }

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.getElementById('video-container').append(canvas);
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
                
                if(detections.length > 0) {
                    status.style.color = "green";
                    status.innerText = "Rosto Detectado!";
                } else {
                    status.style.color = "red";
                    status.innerText = "Nenhum rosto visível...";
                }
            }, 200);
        });
    </script>
</body>
</html>
