<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teste Facial Radar</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; background: #f0f2f5; padding: 20px; }
        #video-container { position: relative; border-radius: 15px; overflow: hidden; box-shadow: 0 8px 20px rgba(0,0,0,0.2); background: #000; width: 320px; height: 240px; }
        video, canvas { position: absolute; top: 0; left: 0; }
        #status { margin-bottom: 15px; padding: 10px; border-radius: 8px; font-weight: bold; background: white; width: 300px; text-align: center; }
        .error { color: #dc2626; border: 1px solid #dc2626; }
        .success { color: #16a34a; }
    </style>
</head>
<body>

    <div id="status">Iniciando sistema...</div>
    
    <div id="video-container">
        <video id="video" width="320" height="240" autoplay muted playsinline></video>
    </div>

    <script>
        const video = document.getElementById('video');
        const status = document.getElementById('status');

        async function iniciar() {
            try {
                status.innerText = "‚è≥ Carregando modelos da pasta /models...";
                
                // Carregando os modelos com tratamento de erro individual
                await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
                
                status.innerText = "‚úÖ Modelos carregados! Abrindo c√¢mera...";
                status.className = "success";

                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: "user" } 
                });
                video.srcObject = stream;
            } catch (err) {
                status.innerText = "‚ùå ERRO: Verifique se os nomes dos arquivos na pasta /models est√£o corretos no GitHub.";
                status.className = "error";
                console.error(err);
            }
        }

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.getElementById('video-container').append(canvas);
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
                
                if(detections.length > 0) {
                    status.innerText = "üë§ ROSTO DETECTADO";
                    status.style.backgroundColor = "#dcfce7";
                } else {
                    status.innerText = "üîç PROCURANDO ROSTO...";
                    status.style.backgroundColor = "white";
                }
            }, 200);
        });

        iniciar();
    </script>
</body>
</html>
